# 真正的逐帧解说功能实现计划

## 📋 需求总结

你需要的逐帧解说功能：
- ✅ **保留原视频所有内容**（73.7秒完整）
- ✅ **只在需要解说的片段叠加配音和字幕**
- ✅ **不需要解说的片段保持纯原声**（可选：静音原声）
- ❌ **不裁剪视频**（当前实现的问题）

## 🔍 当前架构分析

### 现状：所有解说模式都使用"裁剪+合并"

当前流程（所有模式）:
1. 提取关键帧/读取字幕
2. 生成脚本（包含时间戳）
3. 生成TTS音频和字幕
4. 裁剪视频片段 (clip_video_unified)
5. 合并片段 (combine_clip_videos)
6. 叠加音频和字幕 (merge_materials) ← 这个只是处理音轨和字幕轨

**问题**：
- 即使短剧解说也使用了"裁剪+合并"
- 如果脚本时间戳没有覆盖完整视频，会有内容丢失
- 这不是"真正意义上"的"在原视频上叠加配音"

## 🎯 需要的新功能

### 功能：叠加配音到完整原视频

新流程：
1. 提取关键帧
2. 视觉分析生成脚本
3. 生成TTS音频和字幕（只包含需要解说的片段）
4. ✅ 直接在原视频上叠加音频和字幕（不裁剪！）
5. 输出完整视频（73.7秒）

### 核心差异

| 当前实现 | 新实现 |
|---------|--------|
| 裁剪视频 → 合并片段 → 叠加音频 | 直接在原视频叠加音频（不裁剪）|
| 视频时长 = 脚本覆盖时长 | 视频时长 = 原视频时长 |
| 可能丢失内容 | 完整保留内容 |
| 适用场景：短视频剪辑 | 适用场景：逐帧解说 |

## ❓ 需要确认的问题

1. 是否所有解说模式都应该支持"叠加配音模式"？
2. "叠加配音模式"是否应该成为默认选项？
3. "静音原声"的默认行为是什么？

请回答这3个问题，我将创建详细的实施计划！
